{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/avyaymc/Convolutional-Visual-Prompts/blob/main/contrastive.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#imports"
      ],
      "metadata": {
        "id": "EQMaWXiz2b6o"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XAhueIa4vypD"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import models\n",
        "from torchvision.transforms import Compose, Resize, ToTensor, Normalize"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "!pip install tqdm\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EfXlW2xHv4A4",
        "outputId": "804ab1ed-c9b9-4a2b-df57-9f3f67b68584"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.65.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Data"
      ],
      "metadata": {
        "id": "KSOMDvOV2es4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from torchvision.transforms import ToTensor\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "class CIFAR10C(Dataset):\n",
        "    def __init__(self, corruption_npy, labels_npy, transform=None):\n",
        "        self.images = np.load(corruption_npy)\n",
        "        self.labels = np.load(labels_npy)\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image = self.images[idx]\n",
        "        label = self.labels[idx]\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, label"
      ],
      "metadata": {
        "id": "M6ht27MYv5e_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "data_folder = \"/content/drive/MyDrive/CIFAR-10-C/\"\n",
        "\n",
        "labels_npy = f\"{data_folder}/labels.npy\"\n",
        "\n",
        "corruption_file = \"fog.npy\"\n",
        "\n",
        "\n",
        "corruption_npy = f\"{data_folder}/{corruption_file}\"\n",
        "\n",
        "te= np.load(corruption_npy)\n",
        "shape=te.shape\n",
        "print(\"shape:\", shape)\n",
        "corruption_name = corruption_file[:-4]\n",
        "datasets = {corruption_name: CIFAR10C(corruption_npy, labels_npy, transform=ToTensor())}\n",
        "\n",
        "# Save the fine-tuned model\n",
        "#model_path = '/content/drive/MyDrive/resnet18_cifar10_finetuned.pth'\n",
        "#torch.save(resnet18_cifar10.state_dict(), model_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aGP7do_KwALe",
        "outputId": "baad0488-f48e-44e4-fd50-d758d32669d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "shape: (50000, 32, 32, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.datasets import cifar10\n",
        "\n",
        "(x_train, y_train), (_, _) = cifar10.load_data()\n",
        "severity_level = 1\n",
        "filtered_indices = np.where(y_train[:, 0] == severity_level)[0][:10000]\n",
        "x_filtered = x_train[filtered_indices]\n"
      ],
      "metadata": {
        "id": "ciArCLoWQ4RK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e72d9f6-deb1-4597-edcf-0047d335e85b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170498071/170498071 [==============================] - 16s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_images_to_visualize = 5\n",
        "random_indices = np.random.choice(range(len(x_filtered)), num_images_to_visualize, replace=False)\n"
      ],
      "metadata": {
        "id": "52XfYjVjRCOx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "for i, idx in enumerate(random_indices):\n",
        "    plt.subplot(1, num_images_to_visualize, i+1)\n",
        "    plt.imshow(x_filtered[idx])\n",
        "    plt.axis('off')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K3iT2NKzREvq",
        "outputId": "00affc85-2918-4bb4-c66f-c4b9a0ccfcdc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x500 with 5 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#models"
      ],
      "metadata": {
        "id": "iIDdM_rb2jmY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The only difference being the absence of the self supervised model and using contrastive loss alone\n"
      ],
      "metadata": {
        "id": "IfgA20f_2mIH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "model_save_path = \"/content/drive/MyDrive/resnet18_cifar10_finetuned.pth\"\n",
        "#model_save_path = '/content/drive/MyDrive/resnet18_cifar10_c_finetuned.pth'\n",
        "\n",
        "def resnet18_cifar():\n",
        "    model = models.resnet18(pretrained=True)\n",
        "    model.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "    model.maxpool = nn.Identity()\n",
        "    model.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "    model.fc = nn.Linear(512, 10)\n",
        "    return model\n",
        "\n",
        "\n",
        "resnet18_cifar10 = resnet18_cifar().to(device)\n",
        "\n",
        "\n",
        "resnet18_cifar10.load_state_dict(torch.load(model_save_path))\n",
        "#resnet18_cifar10.load_state_dict(torch.load(model_save_path, map_location=torch.device('cpu')))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5XjN0dPvwCEm",
        "outputId": "bbb0bb18-3c36-46a3-9da0-7fae869aa830"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
            "100%|██████████| 44.7M/44.7M [00:00<00:00, 128MB/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "def contrastive_loss(z, y, tau=0.1, epsilon=1e-8):\n",
        "    z = F.normalize(z, dim=1)\n",
        "    cos_sim = torch.matmul(z, z.T) / (torch.norm(z, dim=1).unsqueeze(1) * torch.norm(z, dim=1).unsqueeze(0) + epsilon)\n",
        "\n",
        "    mask = (y.unsqueeze(1) == y.unsqueeze(0)).float()\n",
        "    mask.fill_diagonal_(0)\n",
        "\n",
        "    cos_sim_max = torch.max(cos_sim, dim=1, keepdim=True)[0]\n",
        "    cos_sim_exp = torch.exp((cos_sim - cos_sim_max) / tau)\n",
        "    cos_sim_exp_sum = cos_sim_exp.sum(1) - torch.diag(cos_sim_exp)\n",
        "    cos_sim_exp_sum_positive = torch.sum(cos_sim_exp * mask, dim=1)\n",
        "\n",
        "    loss = torch.log(cos_sim_exp_sum + epsilon) - torch.log(cos_sim_exp_sum_positive + epsilon)\n",
        "    loss = loss.mean()\n",
        "\n",
        "    return loss\n"
      ],
      "metadata": {
        "id": "eOmvAhNyw5qO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ResNetFeatures(nn.Module):\n",
        "    def __init__(self, original_model, layer_index):\n",
        "        super(ResNetFeatures, self).__init__()\n",
        "        self.features = nn.Sequential(*list(original_model.children())[:-1])\n",
        "        self.layer_index = layer_index\n",
        "\n",
        "    def forward(self, x):\n",
        "        for idx, layer in enumerate(self.features):\n",
        "            x = layer(x)\n",
        "            if idx == self.layer_index:\n",
        "                break\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "A_ful2Zdw6jf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_last_conv_layer(module):\n",
        "    if isinstance(module, nn.Conv2d):\n",
        "        return module\n",
        "    elif isinstance(module, nn.Sequential) or isinstance(module, nn.Module):\n",
        "        children = list(module.children())\n",
        "        for child in reversed(children):\n",
        "            result = get_last_conv_layer(child)\n",
        "            if result is not None:\n",
        "                return result\n",
        "    return None\n",
        "\n",
        "layer_index = len(list(resnet18_cifar10.children())) - 2\n",
        "last_conv_layer = get_last_conv_layer(resnet18_cifar10)\n",
        "\n",
        "layer_input_channels = last_conv_layer.out_channels if last_conv_layer is not None else None\n",
        "\n",
        "resnet18_cifar10_features = ResNetFeatures(resnet18_cifar10, layer_index)\n",
        "print(\"Last layer output channels:\", layer_input_channels)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_a4bxRbeLOsL",
        "outputId": "7f254226-a574-4d8e-89c6-a0a4a99b1165"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Last layer output channels: 512\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "    sample_input = torch.randn(1, 3, 32, 32).to(device)\n",
        "    sample_output = resnet18_cifar10_features(sample_input)\n",
        "    feature_shape = sample_output.shape[1:]\n",
        "    feature_dim = torch.prod(torch.tensor(feature_shape)).item()\n",
        "    print(\"Feature shape:\", feature_shape)\n",
        "    print(\"Feature dim:\", feature_dim)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p3CTKpgTxDJt",
        "outputId": "b2952f42-12e9-4e3c-d8f1-f93931607e75"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature shape: torch.Size([512, 1, 1])\n",
            "Feature dim: 512\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class ConvKernel(nn.Module):\n",
        "    def __init__(self, kernel_size, in_channels, out_channels):\n",
        "        super(ConvKernel, self).__init__()\n",
        "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size, stride=1, padding=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.conv(x)"
      ],
      "metadata": {
        "id": "FzkgVd8K-cKe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ResNetClassifier(nn.Module):\n",
        "    def __init__(self, original_model):\n",
        "        super(ResNetClassifier, self).__init__()\n",
        "        self.classifier = nn.Sequential(*list(original_model.children())[-1:])\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.classifier(x)\n",
        "        return x\n",
        "resnet18_cifar10_classifier = ResNetClassifier(resnet18_cifar10).to(device)"
      ],
      "metadata": {
        "id": "OLhTSZCfsnvV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#training"
      ],
      "metadata": {
        "id": "GBeYkOuP2uJ5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_conv_kernel(dataloader, model, classifier, device, learning_rate, contrastive_loss_fn, kernel_optimization_steps=1500):\n",
        "    model.eval()\n",
        "    classifier.eval()\n",
        "\n",
        "    for i, data in enumerate(dataloader, 0):\n",
        "        inputs, labels = data\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        conv_kernel_module = ConvKernel(kernel_size=3,\n",
        "                                in_channels=layer_input_channels,\n",
        "                                out_channels=layer_input_channels).to(device)\n",
        "\n",
        "        # Initialize the kernel parameters from a uniform distribution\n",
        "        for param in conv_kernel_module.parameters():\n",
        "            param.data.uniform_(-1.0, 1.0)\n",
        "\n",
        "        optimizer = torch.optim.SGD(conv_kernel_module.parameters(), lr=learning_rate, momentum=0.9, weight_decay=1e-5)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            features = model(inputs)\n",
        "        initial_loss = contrastive_loss_fn(features.view(features.size(0), -1), labels)\n",
        "\n",
        "        # Save the initial state of the convolutional kernel\n",
        "        initial_state_dict = conv_kernel_module.state_dict()\n",
        "\n",
        "        for t in range(kernel_optimization_steps):\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            prompted_features = conv_kernel_module(features)\n",
        "\n",
        "            prompted_features_flattened = prompted_features.view(prompted_features.size(0), -1)\n",
        "\n",
        "            loss = contrastive_loss_fn(prompted_features_flattened, labels)\n",
        "\n",
        "            loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(conv_kernel_module.parameters(), 1.0)\n",
        "            optimizer.step()\n",
        "\n",
        "            if t == kernel_optimization_steps - 1:\n",
        "                final_loss = loss.item()\n",
        "\n",
        "        # If the final loss is greater than the initial loss, use the initial kernel parameters\n",
        "        if final_loss > initial_loss.item():\n",
        "            conv_kernel_module.load_state_dict(initial_state_dict)\n",
        "\n",
        "        prompted_features = conv_kernel_module(features)\n",
        "        prompted_features_flattened = prompted_features.view(prompted_features.size(0), -1)\n",
        "\n",
        "        outputs = classifier(prompted_features_flattened)\n",
        "\n",
        "        _, predicted_labels = torch.max(outputs, 1)\n",
        "        correct = (predicted_labels == labels).sum().item()\n",
        "        accuracy = 100 * correct / labels.size(0)\n",
        "\n",
        "        print(f'Batch [{i + 1}/{len(dataloader)}], Loss: {final_loss:.4f}, Accuracy: {accuracy:.2f}%')\n"
      ],
      "metadata": {
        "id": "ecgBCsj5s7Vo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = 0.001\n",
        "batch_size = 25\n",
        "accumulation_steps = 4\n",
        "corrupted_dataloader = torch.utils.data.DataLoader(datasets['fog'], batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "projection_dim = 512\n",
        "\n",
        "# Load the entire dataset\n",
        "full_dataset = CIFAR10C(corruption_npy, labels_npy, transform=ToTensor())\n",
        "\n",
        "# Create a subset for severity 1\n",
        "severity1_dataset = torch.utils.data.Subset(full_dataset, range(10000))\n",
        "\n",
        "# Create a DataLoader for the subset\n",
        "severity1_dataloader = torch.utils.data.DataLoader(severity1_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "\n",
        "# Train the model on the DataLoader\n",
        "train_conv_kernel(severity1_dataloader, resnet18_cifar10_features, resnet18_cifar10_classifier, device, learning_rate, contrastive_loss)\n",
        "\n",
        "\n",
        "#train_conv_kernel(corrupted_dataloader, resnet18_cifar10_features, resnet18_cifar10_classifier, device, learning_rate, contrastive_loss)\n"
      ],
      "metadata": {
        "id": "4GtwooF7wv4W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision.datasets import CIFAR10\n",
        "\n",
        "# Define the transform\n",
        "transform = Compose([\n",
        "    ToTensor(),\n",
        "    Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  # Normalize to range [-1, 1]\n",
        "])\n",
        "\n",
        "# Load the non-corrupted CIFAR10 dataset\n",
        "non_corrupted_dataset = CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "\n",
        "# Create a DataLoader for the non-corrupted dataset\n",
        "non_corrupted_dataloader = torch.utils.data.DataLoader(non_corrupted_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "\n",
        "# Train the model on the DataLoader\n",
        "train_conv_kernel(non_corrupted_dataloader, resnet18_cifar10_features, resnet18_cifar10_classifier, device, learning_rate, contrastive_loss)\n"
      ],
      "metadata": {
        "id": "nv9ZAjmfq8Vm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(dataloader, model, device):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i, data in enumerate(dataloader, 0):\n",
        "            inputs, labels = data\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            outputs = model(inputs)\n",
        "\n",
        "            _, predicted_labels = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted_labels == labels).sum().item()\n",
        "\n",
        "            batch_accuracy = 100 * correct / total\n",
        "            print(f'Batch [{i + 1}/{len(dataloader)}], Accuracy: {batch_accuracy:.2f}%')\n",
        "\n",
        "    overall_accuracy = 100 * correct / total\n",
        "    print(f'Overall Accuracy: {overall_accuracy:.2f}%')\n",
        "\n",
        "\n",
        "evaluate_model(corrupted_dataloader, resnet18_cifar10, device)\n"
      ],
      "metadata": {
        "id": "vHTq70Dsvu35",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "fb0e1278-cb90-416c-cfd1-6eeb9d9e1ac6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch [1/2000], Accuracy: 36.00%\n",
            "Batch [2/2000], Accuracy: 40.00%\n",
            "Batch [3/2000], Accuracy: 41.33%\n",
            "Batch [4/2000], Accuracy: 38.00%\n",
            "Batch [5/2000], Accuracy: 41.60%\n",
            "Batch [6/2000], Accuracy: 46.00%\n",
            "Batch [7/2000], Accuracy: 43.43%\n",
            "Batch [8/2000], Accuracy: 45.00%\n",
            "Batch [9/2000], Accuracy: 44.89%\n",
            "Batch [10/2000], Accuracy: 44.80%\n",
            "Batch [11/2000], Accuracy: 46.91%\n",
            "Batch [12/2000], Accuracy: 47.33%\n",
            "Batch [13/2000], Accuracy: 46.15%\n",
            "Batch [14/2000], Accuracy: 46.29%\n",
            "Batch [15/2000], Accuracy: 46.40%\n",
            "Batch [16/2000], Accuracy: 47.25%\n",
            "Batch [17/2000], Accuracy: 47.06%\n",
            "Batch [18/2000], Accuracy: 48.22%\n",
            "Batch [19/2000], Accuracy: 48.21%\n",
            "Batch [20/2000], Accuracy: 47.80%\n",
            "Batch [21/2000], Accuracy: 47.24%\n",
            "Batch [22/2000], Accuracy: 46.55%\n",
            "Batch [23/2000], Accuracy: 46.09%\n",
            "Batch [24/2000], Accuracy: 46.33%\n",
            "Batch [25/2000], Accuracy: 46.24%\n",
            "Batch [26/2000], Accuracy: 46.92%\n",
            "Batch [27/2000], Accuracy: 46.96%\n",
            "Batch [28/2000], Accuracy: 47.71%\n",
            "Batch [29/2000], Accuracy: 47.86%\n",
            "Batch [30/2000], Accuracy: 47.73%\n",
            "Batch [31/2000], Accuracy: 47.87%\n",
            "Batch [32/2000], Accuracy: 48.62%\n",
            "Batch [33/2000], Accuracy: 48.48%\n",
            "Batch [34/2000], Accuracy: 48.12%\n",
            "Batch [35/2000], Accuracy: 47.89%\n",
            "Batch [36/2000], Accuracy: 48.00%\n",
            "Batch [37/2000], Accuracy: 48.22%\n",
            "Batch [38/2000], Accuracy: 48.21%\n",
            "Batch [39/2000], Accuracy: 48.51%\n",
            "Batch [40/2000], Accuracy: 48.50%\n",
            "Batch [41/2000], Accuracy: 48.49%\n",
            "Batch [42/2000], Accuracy: 48.29%\n",
            "Batch [43/2000], Accuracy: 48.09%\n",
            "Batch [44/2000], Accuracy: 48.00%\n",
            "Batch [45/2000], Accuracy: 47.73%\n",
            "Batch [46/2000], Accuracy: 47.74%\n",
            "Batch [47/2000], Accuracy: 47.66%\n",
            "Batch [48/2000], Accuracy: 47.67%\n",
            "Batch [49/2000], Accuracy: 47.76%\n",
            "Batch [50/2000], Accuracy: 47.68%\n",
            "Batch [51/2000], Accuracy: 47.61%\n",
            "Batch [52/2000], Accuracy: 47.46%\n",
            "Batch [53/2000], Accuracy: 47.47%\n",
            "Batch [54/2000], Accuracy: 47.41%\n",
            "Batch [55/2000], Accuracy: 47.56%\n",
            "Batch [56/2000], Accuracy: 47.50%\n",
            "Batch [57/2000], Accuracy: 47.37%\n",
            "Batch [58/2000], Accuracy: 47.24%\n",
            "Batch [59/2000], Accuracy: 46.98%\n",
            "Batch [60/2000], Accuracy: 47.07%\n",
            "Batch [61/2000], Accuracy: 47.08%\n",
            "Batch [62/2000], Accuracy: 47.16%\n",
            "Batch [63/2000], Accuracy: 47.05%\n",
            "Batch [64/2000], Accuracy: 46.94%\n",
            "Batch [65/2000], Accuracy: 47.14%\n",
            "Batch [66/2000], Accuracy: 47.09%\n",
            "Batch [67/2000], Accuracy: 46.93%\n",
            "Batch [68/2000], Accuracy: 46.82%\n",
            "Batch [69/2000], Accuracy: 46.67%\n",
            "Batch [70/2000], Accuracy: 46.80%\n",
            "Batch [71/2000], Accuracy: 46.99%\n",
            "Batch [72/2000], Accuracy: 46.94%\n",
            "Batch [73/2000], Accuracy: 46.96%\n",
            "Batch [74/2000], Accuracy: 46.81%\n",
            "Batch [75/2000], Accuracy: 46.88%\n",
            "Batch [76/2000], Accuracy: 46.95%\n",
            "Batch [77/2000], Accuracy: 46.86%\n",
            "Batch [78/2000], Accuracy: 46.87%\n",
            "Batch [79/2000], Accuracy: 47.19%\n",
            "Batch [80/2000], Accuracy: 47.20%\n",
            "Batch [81/2000], Accuracy: 47.11%\n",
            "Batch [82/2000], Accuracy: 47.02%\n",
            "Batch [83/2000], Accuracy: 47.04%\n",
            "Batch [84/2000], Accuracy: 47.10%\n",
            "Batch [85/2000], Accuracy: 46.82%\n",
            "Batch [86/2000], Accuracy: 46.79%\n",
            "Batch [87/2000], Accuracy: 46.85%\n",
            "Batch [88/2000], Accuracy: 46.64%\n",
            "Batch [89/2000], Accuracy: 46.47%\n",
            "Batch [90/2000], Accuracy: 46.53%\n",
            "Batch [91/2000], Accuracy: 46.59%\n",
            "Batch [92/2000], Accuracy: 46.61%\n",
            "Batch [93/2000], Accuracy: 46.54%\n",
            "Batch [94/2000], Accuracy: 46.77%\n",
            "Batch [95/2000], Accuracy: 46.65%\n",
            "Batch [96/2000], Accuracy: 46.58%\n",
            "Batch [97/2000], Accuracy: 46.60%\n",
            "Batch [98/2000], Accuracy: 46.53%\n",
            "Batch [99/2000], Accuracy: 46.46%\n",
            "Batch [100/2000], Accuracy: 46.36%\n",
            "Batch [101/2000], Accuracy: 46.42%\n",
            "Batch [102/2000], Accuracy: 46.43%\n",
            "Batch [103/2000], Accuracy: 46.68%\n",
            "Batch [104/2000], Accuracy: 46.96%\n",
            "Batch [105/2000], Accuracy: 47.09%\n",
            "Batch [106/2000], Accuracy: 47.13%\n",
            "Batch [107/2000], Accuracy: 47.03%\n",
            "Batch [108/2000], Accuracy: 47.11%\n",
            "Batch [109/2000], Accuracy: 47.01%\n",
            "Batch [110/2000], Accuracy: 46.95%\n",
            "Batch [111/2000], Accuracy: 46.92%\n",
            "Batch [112/2000], Accuracy: 46.86%\n",
            "Batch [113/2000], Accuracy: 46.97%\n",
            "Batch [114/2000], Accuracy: 46.91%\n",
            "Batch [115/2000], Accuracy: 46.96%\n",
            "Batch [116/2000], Accuracy: 46.86%\n",
            "Batch [117/2000], Accuracy: 46.77%\n",
            "Batch [118/2000], Accuracy: 46.88%\n",
            "Batch [119/2000], Accuracy: 46.82%\n",
            "Batch [120/2000], Accuracy: 46.77%\n",
            "Batch [121/2000], Accuracy: 46.81%\n",
            "Batch [122/2000], Accuracy: 47.02%\n",
            "Batch [123/2000], Accuracy: 46.93%\n",
            "Batch [124/2000], Accuracy: 46.90%\n",
            "Batch [125/2000], Accuracy: 46.98%\n",
            "Batch [126/2000], Accuracy: 46.95%\n",
            "Batch [127/2000], Accuracy: 46.87%\n",
            "Batch [128/2000], Accuracy: 46.88%\n",
            "Batch [129/2000], Accuracy: 46.79%\n",
            "Batch [130/2000], Accuracy: 47.05%\n",
            "Batch [131/2000], Accuracy: 47.02%\n",
            "Batch [132/2000], Accuracy: 47.18%\n",
            "Batch [133/2000], Accuracy: 47.19%\n",
            "Batch [134/2000], Accuracy: 47.28%\n",
            "Batch [135/2000], Accuracy: 47.32%\n",
            "Batch [136/2000], Accuracy: 47.32%\n",
            "Batch [137/2000], Accuracy: 47.24%\n",
            "Batch [138/2000], Accuracy: 47.13%\n",
            "Batch [139/2000], Accuracy: 47.08%\n",
            "Batch [140/2000], Accuracy: 47.11%\n",
            "Batch [141/2000], Accuracy: 47.15%\n",
            "Batch [142/2000], Accuracy: 47.24%\n",
            "Batch [143/2000], Accuracy: 47.10%\n",
            "Batch [144/2000], Accuracy: 47.08%\n",
            "Batch [145/2000], Accuracy: 47.06%\n",
            "Batch [146/2000], Accuracy: 46.99%\n",
            "Batch [147/2000], Accuracy: 46.88%\n",
            "Batch [148/2000], Accuracy: 46.84%\n",
            "Batch [149/2000], Accuracy: 46.79%\n",
            "Batch [150/2000], Accuracy: 46.83%\n",
            "Batch [151/2000], Accuracy: 46.83%\n",
            "Batch [152/2000], Accuracy: 46.74%\n",
            "Batch [153/2000], Accuracy: 46.80%\n",
            "Batch [154/2000], Accuracy: 46.88%\n",
            "Batch [155/2000], Accuracy: 46.92%\n",
            "Batch [156/2000], Accuracy: 46.92%\n",
            "Batch [157/2000], Accuracy: 47.06%\n",
            "Batch [158/2000], Accuracy: 47.11%\n",
            "Batch [159/2000], Accuracy: 47.25%\n",
            "Batch [160/2000], Accuracy: 47.27%\n",
            "Batch [161/2000], Accuracy: 47.20%\n",
            "Batch [162/2000], Accuracy: 47.23%\n",
            "Batch [163/2000], Accuracy: 47.29%\n",
            "Batch [164/2000], Accuracy: 47.24%\n",
            "Batch [165/2000], Accuracy: 47.22%\n",
            "Batch [166/2000], Accuracy: 47.18%\n",
            "Batch [167/2000], Accuracy: 47.26%\n",
            "Batch [168/2000], Accuracy: 47.26%\n",
            "Batch [169/2000], Accuracy: 47.22%\n",
            "Batch [170/2000], Accuracy: 47.18%\n",
            "Batch [171/2000], Accuracy: 47.20%\n",
            "Batch [172/2000], Accuracy: 47.23%\n",
            "Batch [173/2000], Accuracy: 47.28%\n",
            "Batch [174/2000], Accuracy: 47.26%\n",
            "Batch [175/2000], Accuracy: 47.18%\n",
            "Batch [176/2000], Accuracy: 47.18%\n",
            "Batch [177/2000], Accuracy: 47.23%\n",
            "Batch [178/2000], Accuracy: 47.24%\n",
            "Batch [179/2000], Accuracy: 47.26%\n",
            "Batch [180/2000], Accuracy: 47.24%\n",
            "Batch [181/2000], Accuracy: 47.29%\n",
            "Batch [182/2000], Accuracy: 47.27%\n",
            "Batch [183/2000], Accuracy: 47.26%\n",
            "Batch [184/2000], Accuracy: 47.26%\n",
            "Batch [185/2000], Accuracy: 47.31%\n",
            "Batch [186/2000], Accuracy: 47.27%\n",
            "Batch [187/2000], Accuracy: 47.34%\n",
            "Batch [188/2000], Accuracy: 47.34%\n",
            "Batch [189/2000], Accuracy: 47.39%\n",
            "Batch [190/2000], Accuracy: 47.37%\n",
            "Batch [191/2000], Accuracy: 47.46%\n",
            "Batch [192/2000], Accuracy: 47.50%\n",
            "Batch [193/2000], Accuracy: 47.42%\n",
            "Batch [194/2000], Accuracy: 47.34%\n",
            "Batch [195/2000], Accuracy: 47.28%\n",
            "Batch [196/2000], Accuracy: 47.27%\n",
            "Batch [197/2000], Accuracy: 47.19%\n",
            "Batch [198/2000], Accuracy: 47.11%\n",
            "Batch [199/2000], Accuracy: 47.08%\n",
            "Batch [200/2000], Accuracy: 47.14%\n",
            "Batch [201/2000], Accuracy: 47.12%\n",
            "Batch [202/2000], Accuracy: 47.07%\n",
            "Batch [203/2000], Accuracy: 47.07%\n",
            "Batch [204/2000], Accuracy: 47.12%\n",
            "Batch [205/2000], Accuracy: 47.14%\n",
            "Batch [206/2000], Accuracy: 47.22%\n",
            "Batch [207/2000], Accuracy: 47.27%\n",
            "Batch [208/2000], Accuracy: 47.31%\n",
            "Batch [209/2000], Accuracy: 47.29%\n",
            "Batch [210/2000], Accuracy: 47.24%\n",
            "Batch [211/2000], Accuracy: 47.20%\n",
            "Batch [212/2000], Accuracy: 47.17%\n",
            "Batch [213/2000], Accuracy: 47.14%\n",
            "Batch [214/2000], Accuracy: 47.16%\n",
            "Batch [215/2000], Accuracy: 47.20%\n",
            "Batch [216/2000], Accuracy: 47.26%\n",
            "Batch [217/2000], Accuracy: 47.32%\n",
            "Batch [218/2000], Accuracy: 47.28%\n",
            "Batch [219/2000], Accuracy: 47.42%\n",
            "Batch [220/2000], Accuracy: 47.47%\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-05ef780e7aa6>\u001b[0m in \u001b[0;36m<cell line: 25>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0mevaluate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorrupted_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresnet18_cifar10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-18-05ef780e7aa6>\u001b[0m in \u001b[0;36mevaluate_model\u001b[0;34m(dataloader, model, device)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0mbatch_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mcorrect\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mtotal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Batch [{i + 1}/{len(dataloader)}], Accuracy: {batch_accuracy:.2f}%'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0moverall_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mcorrect\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mtotal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/iostream.py\u001b[0m in \u001b[0;36mwrite\u001b[0;34m(self, string)\u001b[0m\n\u001b[1;32m    400\u001b[0m             \u001b[0mis_child\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_master_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    401\u001b[0m             \u001b[0;31m# only touch the buffer in the IO thread to avoid races\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 402\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpub_thread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mschedule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_buffer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    403\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_child\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    404\u001b[0m                 \u001b[0;31m# mp.Pool cannot be trusted to flush promptly (or ever),\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/iostream.py\u001b[0m in \u001b[0;36mschedule\u001b[0;34m(self, f)\u001b[0m\n\u001b[1;32m    201\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_events\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m             \u001b[0;31m# wake event thread (message content is ignored)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event_pipe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mb''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    204\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m             \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/zmq/sugar/socket.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, data, flags, copy, track, routing_id, group)\u001b[0m\n\u001b[1;32m    616\u001b[0m                 )\n\u001b[1;32m    617\u001b[0m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 618\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrack\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrack\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    619\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    620\u001b[0m     def send_multipart(\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.send\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.send\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket._send_copy\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/zmq/backend/cython/checkrc.pxd\u001b[0m in \u001b[0;36mzmq.backend.cython.checkrc._check_rc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "V1pjgzga3BSe"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}