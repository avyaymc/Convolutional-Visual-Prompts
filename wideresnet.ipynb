{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "collapsed_sections": [
        "fcr-BaKQ-GkE",
        "yCm6Ob_N-Jt7",
        "GohUtywH-Nqk",
        "gd2_q6-h_Xkz"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/avyaymc/Convolutional-Visual-Prompts/blob/main/wideresnet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#imports"
      ],
      "metadata": {
        "id": "fcr-BaKQ-GkE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch torchvision\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i1lTuW0492-b",
        "outputId": "aa49bfab-a51e-4473-e373-1d91cc7c473c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.0.1+cu118)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.15.2+cu118)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.7.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (16.0.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.22.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision) (2.27.1)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (8.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.3)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (3.4)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import models\n",
        "from torchvision.transforms import Compose, Resize, ToTensor, Normalize"
      ],
      "metadata": {
        "id": "w24W5-rH93bN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "!pip install tqdm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lfkc2Tph_Azq",
        "outputId": "6e74627b-30b5-40a9-ea55-746607f3d1a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.65.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#wideresnet definition"
      ],
      "metadata": {
        "id": "yCm6Ob_N-Jt7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class BasicBlock(nn.Module):\n",
        "    def __init__(self, in_planes, out_planes, stride, drop_rate=0.0):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        self.bn1 = nn.BatchNorm2d(in_planes)\n",
        "        self.relu1 = nn.ReLU(inplace=True)\n",
        "        self.conv1 = nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
        "                               padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(out_planes)\n",
        "        self.relu2 = nn.ReLU(inplace=True)\n",
        "        self.conv2 = nn.Conv2d(out_planes, out_planes, kernel_size=3, stride=1,\n",
        "                               padding=1, bias=False)\n",
        "        self.drop_rate = drop_rate\n",
        "        self.equalInOut = (in_planes == out_planes)\n",
        "        self.convShortcut = (not self.equalInOut) and nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride,\n",
        "                               padding=0, bias=False) or None\n",
        "\n",
        "    def forward(self, x):\n",
        "        if not self.equalInOut:\n",
        "            x = self.relu1(self.bn1(x))\n",
        "            out = self.conv1(x)\n",
        "        else:\n",
        "            out = self.conv1(self.relu1(self.bn1(x)))\n",
        "        if self.drop_rate > 0:\n",
        "            out = F.dropout(out, p=self.drop_rate, training=self.training)\n",
        "        out = self.conv2(self.relu2(self.bn2(out)))\n",
        "        if not self.equalInOut:\n",
        "            return torch.add(self.convShortcut(x), out)\n",
        "        else:\n",
        "            return torch.add(x, out)\n"
      ],
      "metadata": {
        "id": "JgiDXMiIF-B_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class NetworkBlock(nn.Module):\n",
        "    def __init__(self, nb_layers, in_planes, out_planes, block, stride, drop_rate=0.0):\n",
        "        super(NetworkBlock, self).__init__()\n",
        "        self.layer = self._make_layer(block, in_planes, out_planes, nb_layers, stride, drop_rate)\n",
        "\n",
        "    def _make_layer(self, block, in_planes, out_planes, nb_layers, stride, drop_rate):\n",
        "        layers = []\n",
        "        for i in range(nb_layers):\n",
        "            layers.append(block(i == 0 and in_planes or out_planes, out_planes, i == 0 and stride or 1, drop_rate))\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.layer(x)\n"
      ],
      "metadata": {
        "id": "I0Q2OhshF-z_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class WideResNet(nn.Module):\n",
        "    def __init__(self, depth, widen_factor, num_classes, drop_rate=0.0):\n",
        "        super(WideResNet, self).__init__()\n",
        "        n_channels = [16, 16 * widen_factor, 32 * widen_factor, 64 * widen_factor]\n",
        "        assert (depth - 4) % 6 == 0, 'Wide-resnet depth should be 6n+4'\n",
        "        n = (depth - 4) // 6\n",
        "        block = BasicBlock\n",
        "        self.conv1 = nn.Conv2d(3, n_channels[0], kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.block1 = NetworkBlock(n, n_channels[0], n_channels[1], block, 1, drop_rate)\n",
        "        self.block2 = NetworkBlock(n, n_channels[1], n_channels[2], block, 2, drop_rate)\n",
        "        self.block3 = NetworkBlock(n, n_channels[2], n_channels[3], block, 2, drop_rate)\n",
        "        self.bn1 = nn.BatchNorm2d(n_channels[3])\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.fc = nn.Linear(n_channels[3], num_classes)\n",
        "        self.n_channels = n_channels[3]\n",
        "\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
        "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                m.weight.data.fill_(1)\n",
        "                m.bias.data.zero_()\n",
        "            elif isinstance(m, nn.Linear):\n",
        "                m.bias.data.zero_()\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.conv1(x)\n",
        "        out = self.block1(out)\n",
        "        out = self.block2(out)\n",
        "        out = self.block3(out)\n",
        "        out = self.relu(self.bn1(out))\n",
        "        out = F.avg_pool2d(out, 8)\n",
        "        out = out.view(-1, self.n_channels)\n",
        "        return self.fc(out)\n"
      ],
      "metadata": {
        "id": "zmQZMDtVGEBe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#data"
      ],
      "metadata": {
        "id": "GohUtywH-Nqk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from torchvision.transforms import ToTensor\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "class CIFAR10C(Dataset):\n",
        "    def __init__(self, corruption_npy, labels_npy, transform=None):\n",
        "        self.images = np.load(corruption_npy)\n",
        "        self.labels = np.load(labels_npy)\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image = self.images[idx]\n",
        "        label = self.labels[idx]\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, label"
      ],
      "metadata": {
        "id": "MQquWAux_RoS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "data_folder = \"/content/drive/MyDrive/CIFAR-10-C/\"\n",
        "\n",
        "labels_npy = f\"{data_folder}/labels.npy\"\n",
        "\n",
        "\n",
        "corruption_file = \"fog.npy\"\n",
        "corruption_npy = f\"{data_folder}/{corruption_file}\"\n",
        "corruption_name = corruption_file[:-4]\n",
        "datasets = {corruption_name: CIFAR10C(corruption_npy, labels_npy, transform=ToTensor())}\n"
      ],
      "metadata": {
        "id": "EzasySQX_TGK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "babaa0f9-b3e8-4d6e-9c8b-144a07466369"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#models"
      ],
      "metadata": {
        "id": "gd2_q6-h_Xkz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import math\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "pretrained_model = WideResNet(depth=28, widen_factor=10, num_classes=10)\n",
        "\n",
        "\n",
        "checkpoint_path = \"/content/drive/MyDrive/cifar10_standard.pth\"\n",
        "checkpoint = torch.load(checkpoint_path)\n",
        "\n",
        "state_dict = checkpoint['state_dict']\n",
        "\n",
        "state_dict = {k.replace(\"module.\", \"\"): v for k, v in state_dict.items()}\n",
        "\n",
        "pretrained_model.load_state_dict(state_dict)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "pretrained_model = pretrained_model.to(device)"
      ],
      "metadata": {
        "id": "aTrAZdOM-Ftb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "662acc84-4537-4e93-ca73-bd367e6c92ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class WideResNetFeatures(nn.Module):\n",
        "    def __init__(self, model, layer_index):\n",
        "        super(WideResNetFeatures, self).__init__()\n",
        "        self.layer_index = layer_index\n",
        "\n",
        "        self.conv1 = model.conv1\n",
        "        self.block1 = model.block1\n",
        "        self.block2 = model.block2\n",
        "        self.block3 = model.block3\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.conv1(x)\n",
        "        if self.layer_index >= 1:\n",
        "            out = self.block1(out)\n",
        "        if self.layer_index >= 2:\n",
        "            out = self.block2(out)\n",
        "        if self.layer_index >= 3:\n",
        "            out = self.block3(out)\n",
        "        return out\n"
      ],
      "metadata": {
        "id": "VFSylslRE5K3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "layer_index = 2\n",
        "pretrained_wrn_features = WideResNetFeatures(pretrained_model, layer_index)\n"
      ],
      "metadata": {
        "id": "mEaLzxr6tLTC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "def contrastive_loss(z, y, tau=0.1, epsilon=1e-8):\n",
        "    z = F.normalize(z, dim=1)\n",
        "    cos_sim = torch.matmul(z, z.T) / (torch.norm(z, dim=1).unsqueeze(1) * torch.norm(z, dim=1).unsqueeze(0) + epsilon)\n",
        "\n",
        "    mask = (y.unsqueeze(1) == y.unsqueeze(0)).float()\n",
        "    mask.fill_diagonal_(0)\n",
        "\n",
        "    cos_sim_max = torch.max(cos_sim, dim=1, keepdim=True)[0]\n",
        "    cos_sim_exp = torch.exp((cos_sim - cos_sim_max) / tau)\n",
        "    cos_sim_exp_sum = cos_sim_exp.sum(1) - torch.diag(cos_sim_exp)\n",
        "    cos_sim_exp_sum_positive = torch.sum(cos_sim_exp * mask, dim=1)\n",
        "\n",
        "    loss = torch.log(cos_sim_exp_sum + epsilon) - torch.log(cos_sim_exp_sum_positive + epsilon)\n",
        "    loss = loss.mean()\n",
        "\n",
        "    return loss\n"
      ],
      "metadata": {
        "id": "h9uIhttMtjVC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ConvKernel(nn.Module):\n",
        "    def __init__(self, kernel_size, in_channels, out_channels, projection_dim):\n",
        "        super(ConvKernel, self).__init__()\n",
        "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size, stride=1, padding=1)\n",
        "        nn.init.kaiming_normal_(self.conv.weight, mode='fan_out', nonlinearity='relu')\n",
        "        self.bn = nn.BatchNorm2d(out_channels)\n",
        "        self.linear_input_size = out_channels * feature_shape[1] * feature_shape[2]\n",
        "        self.linear = nn.Linear(self.linear_input_size, projection_dim)\n",
        "        nn.init.xavier_normal_(self.linear.weight)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        x = self.bn(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.linear(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "txu2qTG9tjxg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#training"
      ],
      "metadata": {
        "id": "5Lv8I2QW0evG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "def train_conv_kernel(dataloader, model, conv_kernel_module, device, num_epochs, learning_rate, layer_index, contrastive_loss_fn, accumulation_steps=4):\n",
        "    optimizer = torch.optim.SGD(conv_kernel_module.parameters(), lr=learning_rate, momentum=0.9, weight_decay=1e-5)\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        running_loss = 0.0\n",
        "\n",
        "        progress_bar = tqdm(enumerate(dataloader), total=len(dataloader), desc=f\"Epoch {epoch+1}/{num_epochs}\")\n",
        "\n",
        "        for i, data in progress_bar:\n",
        "            inputs, labels = data\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            features = model(inputs)\n",
        "\n",
        "            prompted_features = conv_kernel_module(features)\n",
        "\n",
        "            loss = contrastive_loss_fn(prompted_features, labels)\n",
        "\n",
        "            loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(conv_kernel_module.parameters(), 1.0)\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            progress_bar.set_postfix({\"loss\": running_loss / (i + 1)})\n",
        "\n",
        "        print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {running_loss / (i + 1):.4f}')\n",
        "\n"
      ],
      "metadata": {
        "id": "x3sNhItktmUI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "    sample_input = torch.randn(1, 3, 32, 32).to(device)\n",
        "    sample_output = pretrained_wrn_features(sample_input)\n",
        "    feature_shape = sample_output.shape[1:]\n",
        "    feature_dim = torch.prod(torch.tensor(feature_shape)).item()\n",
        "    print(\"Feature shape:\", feature_shape)\n",
        "    print(\"Feature dim:\", feature_dim)\n",
        "\n",
        "# if layer_index == 0:\n",
        "#     layer_input_channels = 3\n",
        "# elif layer_index == 1:\n",
        "#     layer_input_channels = pretrained_wrn_features.block1.layer[-1].conv2.out_channels\n",
        "# elif layer_index == 2:\n",
        "#     layer_input_channels = pretrained_wrn_features.block2.layer[-1].conv2.out_channels\n",
        "# elif layer_index == 3:\n",
        "#     layer_input_channels = pretrained_wrn_features.block3.layer[-1].conv2.out_channels\n",
        "\n",
        "layer_input_channel_map = {\n",
        "    0: 3,\n",
        "    1: pretrained_wrn_features.block1.layer[-1].conv2.out_channels,\n",
        "    2: pretrained_wrn_features.block2.layer[-1].conv2.out_channels,\n",
        "    3: pretrained_wrn_features.block3.layer[-1].conv2.out_channels\n",
        "}\n",
        "\n",
        "layer_input_channels = layer_input_channel_map.get(layer_index)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nb8UXdR0tPKL",
        "outputId": "ca0da793-971d-44fb-c1a5-b68ca16a94a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature shape: torch.Size([320, 16, 16])\n",
            "Feature dim: 81920\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "projection_dim = 64\n",
        "conv_kernel_module = ConvKernel(kernel_size=3, in_channels=layer_input_channels, out_channels=layer_input_channels, projection_dim=projection_dim).to(device)\n"
      ],
      "metadata": {
        "id": "Z5cyERHitRcV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 25\n",
        "corrupted_dataloader = torch.utils.data.DataLoader(datasets['fog'], batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "num_epochs = 10\n",
        "learning_rate = 0.0001\n",
        "# Load the entire dataset\n",
        "full_dataset = CIFAR10C(corruption_npy, labels_npy, transform=ToTensor())\n",
        "\n",
        "# Create a subset for severity 1\n",
        "severity1_dataset = torch.utils.data.Subset(full_dataset, range(10000))\n",
        "\n",
        "# Create a DataLoader for the subset\n",
        "severity1_dataloader = torch.utils.data.DataLoader(severity1_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "\n",
        "train_conv_kernel(severity1_dataloader, pretrained_wrn_features, conv_kernel_module, device, num_epochs, learning_rate, layer_index, contrastive_loss)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JKUyIO2NtVPh",
        "outputId": "99cd3869-b107-4014-a207-5a9ac78bb8a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/10: 100%|██████████| 400/400 [00:37<00:00, 10.77it/s, loss=3.26]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Loss: 3.2599\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch 2/10: 100%|██████████| 400/400 [00:37<00:00, 10.64it/s, loss=3.02]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [2/10], Loss: 3.0247\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch 3/10: 100%|██████████| 400/400 [00:37<00:00, 10.68it/s, loss=2.89]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [3/10], Loss: 2.8944\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch 4/10: 100%|██████████| 400/400 [00:37<00:00, 10.68it/s, loss=2.81]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [4/10], Loss: 2.8057\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch 5/10: 100%|██████████| 400/400 [00:37<00:00, 10.63it/s, loss=2.73]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [5/10], Loss: 2.7252\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch 6/10: 100%|██████████| 400/400 [00:37<00:00, 10.66it/s, loss=2.72]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [6/10], Loss: 2.7199\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch 7/10: 100%|██████████| 400/400 [00:37<00:00, 10.63it/s, loss=2.65]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [7/10], Loss: 2.6519\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch 8/10: 100%|██████████| 400/400 [00:37<00:00, 10.63it/s, loss=2.57]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [8/10], Loss: 2.5679\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch 9/10: 100%|██████████| 400/400 [00:37<00:00, 10.59it/s, loss=2.53]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [9/10], Loss: 2.5321\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch 10/10: 100%|██████████| 400/400 [00:37<00:00, 10.64it/s, loss=2.49]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [10/10], Loss: 2.4867\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6UAE2_VpvPSY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}